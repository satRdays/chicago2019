modalID: 26
title: Peter Cooman
subtitle: Senior Applied Data Scientist at Civis Analytics
date: 1970-01-01
startsAt: 00:00
endsAt: 00:01
img: roundicons.png
preview: Peter_Cooman.jpg
client: Senior Applied Data Scientist at Civis Analytics
clientLink: https://twitter.com/PeterCooman
category: Speaker
description: "Peter Cooman, M.Sc., Ph.D. is a Senior Applied Data Scientist at Civis Analytics. His responsibilities include developing custom solutions to client’s data analytics problems and producing summary statistics, predictive models and reports. Prior to joining Civis, Peter worked at the Rehabilitation Institute of Chicago, where he used robotics and virtual reality to help restore arm movement in individuals who have suffered a stroke. He holds a M.Sc. in Systems and Control Engineering from Delft, University of Technology in the Netherlands and a Ph.D. in Biomedical Engineering from Case Western Reserve University in Cleveland, Ohio."
abstractTitle: "Correcting Bias In Customer Acquisition Models: A Simple And Fair Top-K Ranking Algorithm"
abstract: "We demonstrate how we used a simple and fast re-ordering algorithm for ensuring a fair balance of a protected variable (e.g., race, gender, age) among the Top-k prospects from a rank-ordered list generated by a customer acquisition model.

The acquisition of new customers is a very common business problem, one that machine learning has proven very successful at solving. Typically, a client provides a data set of current customers, we append a sample of non-customers, train a supervised classification model and then use this model to predict a score for all people who live in the client’s footprint. A higher predicted score indicates that an individual is more similar to current customers and therefore would be a better target for marketing outreach. By prioritizing the most likely prospects, outreach efforts become much more efficient, which means clients can either acquire a higher number of customers on the same budget, or acquire the same number of customers for less money.

Because these models are trained on observational data (seeded with current customers), there is a well-known risk that the model will learn and perpetuate existing biases, despite people’s belief that “machines don’t discriminate”. Common approaches like removing the protected features (e.g. race) before training the model, fail to remove this bias, because of the many ways these attributes correlate with other important, but not protected, features (e.g. race and zip code).

We recently worked with a large rental company on identifying likely renters. A comparison of their current residents and the general population in their footprint showed a distinct bias towards Caucasian residents. After training a model on the biased data, we used common R tools (i.e. dplyr) to re-order the prospect list such that the Top k, for any value k, prospects showed the same racial distribution as the general population living in the client’s footprint. To convince our client to use the fairly ranked prospect list, we compared the expected conversion rates between the biased and the fairly ranked prospect lists, which showed that the loss in utility remained small."
talk: true
